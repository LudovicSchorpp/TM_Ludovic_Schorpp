{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy as fp\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "import matplotlib.pyplot as plt\n",
    "from flopy.utils.gridgen import Gridgen \n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "from flopy.utils import Raster\n",
    "import shapely\n",
    "from scipy.optimize import minimize\n",
    "from shapely.geometry import Polygon, Point, LineString, MultiLineString, MultiPoint, MultiPolygon,shape\n",
    "from shapely.strtree import STRtree  \n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.insert(1, '../test_premier_model/')\n",
    "# hand made functions\n",
    "from Rouss1 import *\n",
    "from Rouss2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"working\"\n",
    "model_name = \"Inversion_test\"\n",
    "exe_name= \"../../exe/mf6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_path=\"../../data/shp/limiteModeleRoussillon_poly.shp\" # path to the shp of the aquifer\n",
    "MNT_path= \"../../data/MNT/MNT_50.tif\"\n",
    "MNT20_path = \"../../data/MNT/MNT_20.tif\"\n",
    "Agly_path= \"../../data/Fleuves/Agly_ludo.shp\" # path to Agly\n",
    "Tet_path= \"../../data/Fleuves/Tet_ludo.shp\"\n",
    "Rea_path = \"../../data/Fleuves/Reart_ludo.shp\"\n",
    "Tech_path = \"../../data/Fleuves/Tech_ludo.shp\"\n",
    "Bol_path = \"../../data/Fleuves/Boules_ludo.shp\"\n",
    "Cant_path = \"../../data/Fleuves/Cant_ludo.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial parameters\n",
    "# get x0,y0,y1 and x1 from the DEM\n",
    "x0,y0,x1,y1 = get_MNTbbox(MNT_path)\n",
    "x1 += 4000\n",
    "\n",
    "Lx = x1-x0\n",
    "Ly = y1-y0\n",
    "nlay = 1\n",
    "ncol = nrow = 250\n",
    "delr = np.ones(ncol)*(Lx/ncol)\n",
    "delc = np.ones(nrow)*(Ly/nrow)\n",
    "\n",
    "idomain = np.zeros((nrow*ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load top data\n",
    "MNT = Raster.load(MNT_path)\n",
    "#MNT20 = Raster.load(MNT20_path)\n",
    "\n",
    "grid = fp.discretization.StructuredGrid(delc,delr,xoff=x0,yoff=y0) # create a grid identical to the dis package, will be used\n",
    "                                                                 # to pre-process data\n",
    "\n",
    "top = MNT.resample_to_grid(grid.xcellcenters,\n",
    "                                grid.ycellcenters,\n",
    "                                band = MNT.bands[0],\n",
    "                                method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load botom based on the differents surfaces\n",
    "folder_path = \"../../data/txt_couches\"\n",
    "surfaces = []\n",
    "for file in glob.glob(os.path.join(folder_path, '*.txt')):\n",
    "    Rast = Raster.load(file)\n",
    "    surfaces.append(Rast.resample_to_grid(grid.xcellcenters,\n",
    "                                grid.ycellcenters,\n",
    "                                band = Rast.bands[0],\n",
    "                                method=\"nearest\"))\n",
    "Q = surfaces[1]\n",
    "PC = surfaces[2]\n",
    "PMS = surfaces[3]\n",
    "BOT = PMS.copy()\n",
    "BOT[PMS==-9999] = PC[PMS==-9999]\n",
    "BOT[PC==-9999] = Q[PC==-9999]\n",
    "BOT[BOT==-9999] = top[BOT==-9999] - 50\n",
    "\n",
    "BOT[(top-BOT)<=10] = top[(top-BOT)<=10] - 10 # minimum of 10 m thickness to avoid bug and numerical issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the domain\n",
    "\n",
    "R = gp.read_file(R_path) # import shapefile with geopandas\n",
    "\n",
    "# cells inside the aquifer become active and return the lst of the cellids\n",
    "lst_domain = gp2idomain(R,grid,idomain,area=0) # all the cells of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recharge areas\n",
    "path = \"../../data/recharge/rast_peff2.tif\"\n",
    "rcha = import_rch(path,grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC sea\n",
    "# import the shapefile that correspond to the BC\n",
    "BCsea_path = \"../../data/shp/Sea_BC_L93.shp\"\n",
    "BC_sea = gp.read_file(BCsea_path)\n",
    "\n",
    "# extract cellids from the BC at the sea and make these cells active\n",
    "lst_chd = gp2cellids(grid,BC_sea,idomain,type=\"line\")\n",
    "\n",
    "# attribute a constant head at all the cells in the lst_chd\n",
    "CHD = 0; chd_lst=[];\n",
    "for x in lst_chd:\n",
    "    chd_lst.append((x,CHD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC etangs\n",
    "BCetangs_path = \"../../data/shp/Surface_hydro/SURFACE_HYDROGRAPHIQUE.shp\"\n",
    "Bcet = gp.read_file(BCetangs_path)\n",
    "etangs = Bcet[(Bcet[\"TOPONYME\"]==\"étang de canet\") | (Bcet[\"TOPONYME\"]==\"étang de leucate\")]\n",
    "\n",
    "# extract cellids from the BC \n",
    "etangs_chd = gp2cellids(grid,etangs.dissolve(by=\"NATURE\"),idomain)\n",
    "\n",
    "# attribute a constant head\n",
    "CHD = 0; et_chd_lst=[];\n",
    "for x in etangs_chd:\n",
    "    et_chd_lst.append((x,CHD))\n",
    "    lst_chd.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# rivers\n",
    "\n",
    "# BC Agly\n",
    "Agy_chd = Complete_riv(Agly_path,\"../../data/Fleuves/stations_agly.csv\",us=28,ds=0.1,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)\n",
    "\n",
    "# BC Tet\n",
    "Tet_chd = Complete_riv(Tet_path,\"../../data/Fleuves/stations_tet2.csv\",us=180,ds=0.1,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)\n",
    "\n",
    "#BC Boul\n",
    "Bol_chd = Complete_riv(Bol_path,\"../../data/Fleuves/stations_bol.csv\",us=180,ds=0.1,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)\n",
    "\n",
    "## BC Reart\n",
    "Rea_chd = Complete_riv(Rea_path,\"../../data/Fleuves/stations_reart.csv\",us=130,ds=0,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)\n",
    "\n",
    "## BC Cant\n",
    "Cant_chd = Complete_riv(Cant_path,\"../../data/Fleuves/stations_cant.csv\",us=135,ds=0.1,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)\n",
    "\n",
    "# BC Tech\n",
    "Tech_chd = Complete_riv(Tech_path,\"../../data/Fleuves/stations_tech.csv\",us=170,ds=0.1,lst_chd=lst_chd,\n",
    "                       lst_domain=lst_domain,grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction\n",
    "path = \"../../data/prélèvements/prlvm_brl/Prlvm_brl_Rou.shp\"\n",
    "V_col = \"V Bancaris\"\n",
    "layer = 0\n",
    "stress_data_well = importWells(path,grid,V_col=V_col,layer=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permeability zones based on shp and \n",
    "\n",
    "# initialize arrays that will define the position of the formations\n",
    "idomainQ_rec = np.zeros([nrow*ncol])\n",
    "idomainQ_a = np.zeros([nrow*ncol])\n",
    "idomainPlio = np.zeros([nrow*ncol])\n",
    "\n",
    "pathQr = \"../../data/shp/entités/Alluv_rec.shp\" # shapefile of the Quaternary formations\n",
    "pathQa = \"../../data/shp/entités/Alluv_anc.shp\" #...\n",
    "pathP = \"../../data/shp/entités/Pliocene.shp\"\n",
    "lstIDQ_rec = gp2idomain(gp.read_file(pathQr),grid,idomainQ_rec,area=10) #create the domains of each shp\n",
    "lstIDQ_anc = gp2idomain(gp.read_file(pathQa),grid,idomainQ_a,area=10) \n",
    "lstIDQPlio = gp2idomain(gp.read_file(pathP),grid,idomainPlio,area=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permeability zones\n",
    "\n",
    "\"\"\"\n",
    "create n^2 zones from a given col and row\n",
    "\"\"\"\n",
    "def create_zones(n):\n",
    "    number = n**2\n",
    "    zone = np.zeros([number,nrow,ncol])\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    for irow in np.arange(n):\n",
    "        for icol in np.arange(n):\n",
    "            zone[irow*n+icol][row:row+int(nrow/n),col:col+int(nrow/n)] = 1\n",
    "            col += int(ncol/n)\n",
    "            if icol >= n-1:\n",
    "                col = 0\n",
    "        row += int(nrow/n)\n",
    "        if irow >= n-1:\n",
    "                row = 0\n",
    "    zone = zone.reshape([number,nrow*ncol])\n",
    "\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assing values\n",
    "k = np.ones([nrow*ncol])*1e-5\n",
    "\n",
    "for i in np.arange(number):\n",
    "    k[zone[i]==1] = random.random()*1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define k, different for each lithology\n",
    "\n",
    "kh = 1e-4 # general k\n",
    "kQr = 1e-4 # k for recent Quaternary\n",
    "kQa = 5e-5 # k for ancient Quaternary\n",
    "kp = 2e-5 # k for pliocene\n",
    "\n",
    "k = np.ones([nrow*ncol])*kh # vector containing the permeability array(layer,nrow,ncol)\n",
    "k[idomainPlio==1] = kp\n",
    "k[idomainQ_rec==1] = kQr\n",
    "k[idomainQ_a==1] = kQa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    }
   ],
   "source": [
    "# control piezos\n",
    "piez_path=\"../../data/piezos/pz_hydriad.xlsx\"\n",
    "\n",
    "#import the data using this function (path,modelgrid, sheetname of the data,piezometric level column, x and y coor (in L93 !))\n",
    "Control_pz = importControlPz(piez_path,grid,sheetName=\"1990\",np_col=\"NP\",x_col=\"x\",y_col=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic modules\n",
    "\n",
    "sim = fp.mf6.MFSimulation(sim_name='theis_mf6', version='mf6', exe_name=exe_name, \n",
    "                         sim_ws=model_dir)\n",
    "gwf = fp.mf6.ModflowGwf(sim, modelname=model_name,\n",
    "                           model_nam_file='{}.nam'.format(model_name))\n",
    "dis = fp.mf6.ModflowGwfdis(gwf, nlay=nlay, nrow=nrow, ncol=ncol,\n",
    "                              delr=delr, delc=delc,\n",
    "                              top=top, botm=BOT,xorigin=x0,yorigin=y0,idomain=idomain)\n",
    "\n",
    "tdis = fp.mf6.ModflowTdis(sim, time_units='SECONDS',perioddata=[[1.0, 1, 1.]])\n",
    "ims  = fp.mf6.ModflowIms(sim, print_option='SUMMARY', complexity='moderate')\n",
    "\n",
    "\n",
    "# initial conditions\n",
    "ic   = fp.mf6.ModflowGwfic(gwf,strt=BOT+1)\n",
    "\n",
    "\n",
    "# output control\n",
    "oc   = fp.mf6.ModflowGwfoc(gwf,budget_filerecord='{}.cbc'.format(model_name),\n",
    "                            head_filerecord='{}.hds'.format(model_name),\n",
    "                            saverecord=[('HEAD', 'LAST'),\n",
    "                                        ('BUDGET', 'ALL')],\n",
    "                            printrecord=[('HEAD', 'LAST'),\n",
    "                                         ('BUDGET', 'ALL')])\n",
    "\n",
    "global npf\n",
    "# nodeflowproperty\n",
    "npf  = fp.mf6.ModflowGwfnpf(gwf, icelltype=0,pname=\"npf\", k=k, save_flows=True,save_specific_discharge=True)\n",
    "\n",
    "\n",
    "# recharge\n",
    "rch  = fp.mf6.ModflowGwfrcha(gwf, recharge = rcha/1000/365/86400)\n",
    "   \n",
    "    \n",
    "# well package\n",
    "wel = fp.mf6.ModflowGwfwel(gwf, pname=\"wel\",filename=\"wel.wel\",\n",
    "                           stress_period_data=stress_data_well, maxbound=len(stress_data_well))\n",
    "\n",
    "# constant heads packages\n",
    "chd = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='sea', filename=\"sea.chd\", maxbound=len(chd_lst), \n",
    "                                               stress_period_data={0: chd_lst}, save_flows=True)\n",
    "\n",
    "etangs = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='eta', filename=\"eta.chd\", maxbound=len(et_chd_lst), \n",
    "                                               stress_period_data={0: et_chd_lst}, save_flows=True)\n",
    "\n",
    "Riv1 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='agy', filename=\"agy.chd\", maxbound=len(Agy_chd), \n",
    "                                              stress_period_data={0: Agy_chd}, save_flows=True)\n",
    "\n",
    "Riv2 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='Tet', filename=\"Tet.chd\", maxbound=len(Tet_chd), \n",
    "                                               stress_period_data={0: Tet_chd}, save_flows=True)\n",
    "\n",
    "Riv3 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='Rea', filename=\"Rea.chd\", maxbound=len(Rea_chd), \n",
    "                                               stress_period_data={0: Rea_chd}, save_flows=True)\n",
    "\n",
    "Riv6 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='Cant', filename=\"Cant.chd\", maxbound=len(Cant_chd), \n",
    "                                               stress_period_data={0: Cant_chd}, save_flows=True)\n",
    "\n",
    "Riv4 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='Tech', filename=\"Tech.chd\", maxbound=len(Tech_chd), \n",
    "                                               stress_period_data={0: Tech_chd}, save_flows=True)\n",
    "\n",
    "Riv5 = fp.mf6.modflow.mfgwfchd.ModflowGwfchd(gwf, pname='Bol', filename=\"Bol.chd\", maxbound=len(Bol_chd), \n",
    "                                               stress_period_data={0: Bol_chd}, save_flows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloPy is using the following  executable to run the model: ../../exe/mf6.exe\n",
      "                                   MODFLOW 6\n",
      "                U.S. GEOLOGICAL SURVEY MODULAR HYDROLOGIC MODEL\n",
      "                            VERSION 6.0.4 03/13/2019\n",
      "\n",
      "   MODFLOW 6 compiled Mar 21 2019 15:37:31 with IFORT compiler (ver. 19.0.0)\n",
      "\n",
      "This software has been approved for release by the U.S. Geological \n",
      "Survey (USGS). Although the software has been subjected to rigorous \n",
      "review, the USGS reserves the right to update the software as needed \n",
      "pursuant to further analysis and review. No warranty, expressed or \n",
      "implied, is made by the USGS or the U.S. Government as to the \n",
      "functionality of the software and related material nor shall the \n",
      "fact of release constitute any such warranty. Furthermore, the \n",
      "software is released on condition that neither the USGS nor the U.S. \n",
      "Government shall be held liable for any damages resulting from its \n",
      "authorized or unauthorized use. Also refer to the USGS Water \n",
      "Resources Software User Rights Notice for complete use, copyright, \n",
      "and distribution information.\n",
      "\n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2020/03/27 16:56:37\n",
      "\n",
      " Writing simulation list file: mfsim.lst\n",
      " Using Simulation name file: mfsim.nam\n",
      " Solving:  Stress period:     1    Time step:     1\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2020/03/27 16:56:38\n",
      " Elapsed run time:  0.628 Seconds\n",
      "\n",
      " Normal termination of simulation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.write_simulation(silent=True)\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin the inversions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function that will return the MAE from the model and the control piezometers given certainsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Misfit(kh):\n",
    "    \n",
    "    fp.mf6.mfpackage.MFPackage(gwf,package_type=\"npf\").remove()# remove pre-existing npf package\n",
    "    \n",
    "    k = np.ones([nrow*ncol])*1e-5 # vector containing the permeability array(layer,nrow,ncol)\n",
    "    k[idomainPlio==1] = kh[0]\n",
    "    k[idomainQ_rec==1] = kh[1]\n",
    "    k[idomainQ_a==1] = kh[2]\n",
    "    \n",
    "    npf  = fp.mf6.ModflowGwfnpf(gwf, icelltype=0, k=k) # create the new npf package\n",
    "    npf.write() # write it\n",
    "    if sim.run_simulation(silent = True): # And RUN !\n",
    "        head = get_heads(model_name,model_dir)\n",
    "        head[head>1000]=0\n",
    "    \n",
    "    return np.nanmean(np.abs((Control_pz[Control_pz!=0] - head[0][Control_pz!=0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And minimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kplio : 1.3965203098744751e-05\n",
      "KQrecent : 6.4087076458158e-05\n",
      "KQancient 3.715167817311804e-05 \n",
      "\n",
      "Misfit : 4.428380869995141\n"
     ]
    }
   ],
   "source": [
    "# minimize(Misfit,(kPlio,kQr,kQa),method)\n",
    "res = minimize(Misfit,[(1e-4/10,1e-4,1e-4/3)], method = 'Nelder-Mead')\n",
    "\n",
    "print(\"Kplio : {}\\nKQrecent : {}\\nKQancient {} \\n\\nMisfit : {}\".format(res.x[0],res.x[1],res.x[2],res.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the pz of control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: PendingDeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    }
   ],
   "source": [
    "Control_pz = importControlPz(piez_path,grid,sheetName=\"1960\",np_col=\"NP\",x_col=\"x\",y_col=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kplio : 1.2487935423967033e-05\n",
      "KQrecent : 4.726313005141908e-05\n",
      "KQancient 3.0044723091484874e-05 \n",
      "\n",
      "Misfit : 6.751397862683499\n"
     ]
    }
   ],
   "source": [
    "res = minimize(Misfit,[(1e-4/10,1e-4,1e-4/3)], method = 'Nelder-Mead')\n",
    "\n",
    "print(\"Kplio : {}\\nKQrecent : {}\\nKQancient {} \\n\\nMisfit : {}\".format(res.x[0],res.x[1],res.x[2],res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
